# -*- coding: utf-8 -*-
"""kaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wnRVdMCRWL8gJcXb0egf9SkXnu97HWwv
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
import random
import os

# ================================
# 1. Reproducibility
# ================================

def set_seed(seed=42):
    """Sets the seed for reproducibility."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # Ensures that CUDA selects the same algorithm each time
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# ================================
# 2. Data Loading and Preprocessing
# ================================

# Load the datasets
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# Preprocessing: Separate features and labels
X = train_data.drop(columns=['ID', 'label'])
y = train_data['label']
X_test = test_data.drop(columns=['ID'])

# Check number of classes
num_classes = y.nunique()
print(f"Number of classes: {num_classes}")

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_test_scaled = scaler.transform(X_test)

# Convert the data to PyTorch tensors
X_tensor = torch.tensor(X_scaled, dtype=torch.float32)
y_tensor = torch.tensor(y.values, dtype=torch.long)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)

# ================================
# 3. Model Definition with Residual Connections
# ================================

class ResidualBlock(nn.Module):
    """A residual block with two linear layers and a skip connection."""
    def __init__(self, in_features, out_features, dropout_prob=0.3):
        super(ResidualBlock, self).__init__()
        self.fc1 = nn.Linear(in_features, out_features)
        self.bn1 = nn.BatchNorm1d(out_features)
        self.activation = nn.LeakyReLU()
        self.dropout = nn.Dropout(dropout_prob)
        self.fc2 = nn.Linear(out_features, out_features)
        self.bn2 = nn.BatchNorm1d(out_features)

        # If input and output dimensions differ, adjust the skip connection
        if in_features != out_features:
            self.skip = nn.Linear(in_features, out_features)
        else:
            self.skip = nn.Identity()

    def forward(self, x):
        identity = self.skip(x)
        out = self.activation(self.bn1(self.fc1(x)))
        out = self.dropout(out)
        out = self.activation(self.bn2(self.fc2(out)))
        out += identity
        return out

class EnhancedNeuralNetwork(nn.Module):
    def __init__(self, input_size=64, num_classes=100):
        super(EnhancedNeuralNetwork, self).__init__()
        self.layer1 = ResidualBlock(input_size, 512, dropout_prob=0.3)
        self.layer2 = ResidualBlock(512, 1024, dropout_prob=0.3)
        self.layer3 = ResidualBlock(1024, 512, dropout_prob=0.2)
        self.layer4 = ResidualBlock(512, 256, dropout_prob=0.2)
        self.output_layer = nn.Linear(256, num_classes)

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.output_layer(x)
        return x

# ================================
# 4. Data Augmentation Functions
# ================================

def mixup_data(x, y, alpha=0.3):  # Decreased alpha
    '''
    Applies Mixup augmentation to a batch of inputs and targets.

    Args:
        x (Tensor): Input batch.
        y (Tensor): Target labels.
        alpha (float): Mixup interpolation coefficient.

    Returns:
        mixed_x (Tensor): Mixed inputs.
        y_a (Tensor): Original targets.
        y_b (Tensor): Shuffled targets.
        lam (float): Mixup ratio.
    '''
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)  # Ensure index is on the same device as x

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def add_noise(x, noise_level=0.02):  # Increased noise level
    """Adds Gaussian noise to the inputs."""
    return x + noise_level * torch.randn_like(x)

# ================================
# 5. Training Function with K-Fold Cross-Validation
# ================================

def train_kfold(model_class, X, y, X_test, n_splits=5, epochs=60, batch_size=64, alpha=0.3, learning_rate=5e-5, weight_decay=1e-4, patience=10):
    """
    Trains the model using K-Fold Cross-Validation and returns averaged test predictions.

    Args:
        model_class (nn.Module): The neural network class.
        X (Tensor): Training features.
        y (Tensor): Training labels.
        X_test (Tensor): Test features.
        n_splits (int): Number of folds.
        epochs (int): Number of epochs.
        batch_size (int): Batch size.
        alpha (float): Mixup alpha.
        learning_rate (float): Initial learning rate.
        weight_decay (float): Weight decay for optimizer.
        patience (int): Early stopping patience.

    Returns:
        final_predictions (np.array): Averaged predictions on the test set.
    """
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    test_predictions = np.zeros((X_test.size(0), num_classes))  # Initialize with zeros

    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        print(f"\n===== Fold {fold+1} / {n_splits} =====")
        # Split data
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # Create TensorDatasets
        train_dataset = TensorDataset(X_train, y_train)
        val_dataset = TensorDataset(X_val, y_val)

        # Create DataLoaders
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

        # Initialize the model, loss function, optimizer, and scheduler
        model = model_class(input_size=X.size(1), num_classes=num_classes).to(device)
        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Added label smoothing
        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)

        # Early Stopping variables
        best_val_loss = np.inf
        epochs_no_improve = 0
        best_model_path = f'best_model_fold_{fold+1}.pth'

        for epoch in range(epochs):
            model.train()
            running_loss = 0.0
            correct_train = 0
            total_train = 0

            for inputs, labels in train_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                # Apply Gaussian Noise
                inputs = add_noise(inputs, noise_level=0.02)  # Increased noise level

                # Apply Mixup with adjusted alpha
                mixed_inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=alpha)
                optimizer.zero_grad()
                outputs = model(mixed_inputs)
                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)
                loss.backward()

                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                optimizer.step()
                running_loss += loss.item()

                # Compute training accuracy
                _, predicted = torch.max(outputs, 1)
                total_train += labels.size(0)
                correct_train += (lam * (predicted == targets_a).sum().item() +
                                  (1 - lam) * (predicted == targets_b).sum().item())

            train_loss = running_loss / len(train_loader)
            train_accuracy = 100 * correct_train / total_train

            # Validation phase
            model.eval()
            val_loss = 0.0
            correct_val = 0
            total_val = 0
            with torch.no_grad():
                for inputs, labels in val_loader:
                    inputs, labels = inputs.to(device), labels.to(device)
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item()

                    _, predicted = torch.max(outputs, 1)
                    total_val += labels.size(0)
                    correct_val += (predicted == labels).sum().item()

            val_loss /= len(val_loader)
            val_accuracy = 100 * correct_val / total_val

            print(f"Epoch [{epoch+1}/{epochs}], "
                  f"Train Loss: {train_loss:.4f}, "
                  f"Train Acc: {train_accuracy:.2f}%, "
                  f"Val Loss: {val_loss:.4f}, "
                  f"Val Acc: {val_accuracy:.2f}%")

            # Scheduler step
            scheduler.step(val_loss)

            # Early Stopping check
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                epochs_no_improve = 0
                # Save the best model
                torch.save(model.state_dict(), best_model_path)
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= patience:
                    print("Early stopping triggered.")
                    break

        # Load the best model for this fold securely
        state_dict = torch.load(best_model_path, map_location=device)
        model.load_state_dict(state_dict)
        model.eval()

        # Initialize fold_predictions for this fold
        fold_predictions = np.zeros((X_test.size(0), num_classes))

        # Process test data
        with torch.no_grad():
            test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=False)
            start_idx = 0  # To keep track of the current index in fold_predictions
            for inputs in test_loader:
                inputs = inputs.to(device)
                outputs = model(inputs)
                probabilities = torch.softmax(outputs, dim=1)
                batch_size_actual = inputs.size(0)
                fold_predictions[start_idx:start_idx + batch_size_actual] += probabilities.cpu().numpy()
                start_idx += batch_size_actual

        # Average fold predictions
        test_predictions += fold_predictions / n_splits

        # Cleanup
        del model
        torch.cuda.empty_cache()

    return test_predictions

# ================================
# 6. Device Configuration
# ================================

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ================================
# 7. Training and Generating Predictions
# ================================

# Initialize test predictions
test_preds = train_kfold(
    model_class=EnhancedNeuralNetwork,
    X=X_tensor,
    y=y_tensor,
    X_test=X_test_tensor,
    n_splits=5,
    epochs=60,
    batch_size=64,
    alpha=0.3,
    learning_rate=5e-5,
    weight_decay=1e-4,
    patience=10
)

# ================================
# 8. Preparing Submission
# ================================

# Get the predicted class for each test sample
final_predictions = np.argmax(test_preds, axis=1)

# Prepare the submission file
submission = pd.DataFrame({
    'ID': test_data['ID'],
    'label': final_predictions
})

# Save the predictions to a CSV file
submission.to_csv('kaggle_submission.csv', index=False)

print("Submission file 'kaggle_submission.csv' has been created successfully.")

